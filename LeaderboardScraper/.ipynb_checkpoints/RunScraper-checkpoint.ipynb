{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b23452e-f9ec-4023-bf00-ccd5b6dd1f21",
   "metadata": {},
   "source": [
    "# Leaderboard Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec8e86-a7c5-402a-bf63-8ac78ab6afb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the Scraper\n",
    "<span style=\"color:red\">Note: If you see a \"ReactorNotRestartable\" error, press the refresh button to restart the Kernel.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbe3d8-591b-4e41-90aa-1d9367200040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from twisted.internet import reactor, defer\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from scrapy.utils.log import configure_logging\n",
    "from scrapy.utils.project import get_project_settings\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time \n",
    "\n",
    "CURRENT_WORKING_DIR = os.path.abspath(os.getcwd())\n",
    "INPUT_DIRECTORY = 'AddLeaderboardFiles'\n",
    "FULL_INPUT_DIRECTORY_PATH = '{}/{}'.format(CURRENT_WORKING_DIR, INPUT_DIRECTORY)\n",
    "\n",
    "settings = get_project_settings()\n",
    "configure_logging(settings)\n",
    "runner = CrawlerRunner(settings)\n",
    "\n",
    "@defer.inlineCallbacks\n",
    "def scrape_files():\n",
    "    files = [f for f in listdir(FULL_INPUT_DIRECTORY_PATH) if isfile(join(FULL_INPUT_DIRECTORY_PATH, f))]\n",
    "    if len(files) == 0:\n",
    "        reactor.stop()\n",
    "    else:\n",
    "        file_to_scrape = \"file://{}/{}\".format(FULL_INPUT_DIRECTORY_PATH, files[0])\n",
    "        print(file_to_scrape)\n",
    "        yield runner.crawl('leaderboard', file_name=file_to_scrape)\n",
    "        scrape_files()\n",
    "\n",
    "\n",
    "files = [f for f in listdir(FULL_INPUT_DIRECTORY_PATH) if isfile(join(FULL_INPUT_DIRECTORY_PATH, f))]\n",
    "if len(files) == 0:\n",
    "    print(\"OOPS! You need to add files to scrape.\")\n",
    "else:\n",
    "    scrape_files()\n",
    "    reactor.run()\n",
    "    print(\"\\nSUCCESS! Scraping finished. :)\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412220b-9fe4-4428-9457-a7efc809c230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0cdb9-7d62-4c89-9b5c-e33b0d0f9e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
